{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this exercise you will train a CNN on the FULL Cats-v-dogs dataset\n",
    "# This will require you doing a lot of data preprocessing because\n",
    "# the dataset isn't split into training and validation for you\n",
    "# This code block has all the required inputs\n",
    "#Cat = melanoma y Dog = benign\n",
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from shutil import copyfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.getcwd()\n",
    "\n",
    "# Directorios de clases (10 clases)\n",
    "clases = ['piel-normal', 'lunar', 'melanoma', 'acne', 'carcinoma-de-celulas-escamosas', 'varicela', \n",
    "          'piel-quemada', 'queratosis-actinica', 'carcinoma-de-celulas-basales', 'queratosis-seborreica']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear las carpetas de entrenamiento y validación para las 10 clases\n",
    "try:\n",
    "    os.mkdir(os.path.join(base_dir, 'diagnostico'))\n",
    "    os.mkdir(os.path.join(base_dir, 'diagnostico', 'training'))\n",
    "    os.mkdir(os.path.join(base_dir, 'diagnostico', 'testing'))\n",
    "\n",
    "    for clase in clases:\n",
    "        os.mkdir(os.path.join(base_dir, 'diagnostico', 'training', clase))\n",
    "        os.mkdir(os.path.join(base_dir, 'diagnostico', 'testing', clase))\n",
    "\n",
    "except OSError as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para dividir los datos en entrenamiento y prueba\n",
    "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
    "    files = []\n",
    "    for filename in os.listdir(SOURCE):\n",
    "        file = os.path.join(SOURCE, filename)\n",
    "        if os.path.getsize(file) > 0:\n",
    "            files.append(filename)\n",
    "        else:\n",
    "            print(filename + \" is zero length, so ignoring.\")\n",
    "\n",
    "    training_length = int(len(files) * SPLIT_SIZE)\n",
    "    testing_length = len(files) - training_length\n",
    "    shuffled_set = random.sample(files, len(files))\n",
    "    training_set = shuffled_set[0:training_length]\n",
    "    testing_set = shuffled_set[training_length:]\n",
    "\n",
    "    for filename in training_set:\n",
    "        this_file = os.path.join(SOURCE, filename)\n",
    "        destination = os.path.join(TRAINING, filename)\n",
    "        copyfile(this_file, destination)\n",
    "\n",
    "    for filename in testing_set:\n",
    "        this_file = os.path.join(SOURCE, filename)\n",
    "        destination = os.path.join(TESTING, filename)\n",
    "        copyfile(this_file, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide los datos para las 10 clases\n",
    "try:\n",
    "    \n",
    "    split_size = .95\n",
    "    for clase in clases:\n",
    "        source_dir = os.path.join(base_dir, \"diagnostico-dataset\", clase)\n",
    "        training_dir = os.path.join(base_dir, \"diagnostico\", \"training\", clase)\n",
    "        testing_dir = os.path.join(base_dir, \"diagnostico\", \"testing\", clase)\n",
    "        split_data(source_dir, training_dir, testing_dir, split_size)\n",
    "except OSError as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construcción del modelo actualizado\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(512, (3, 3), activation='relu'),  # Nueva capa con más filtros\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')  # 10 clases con softmax\n",
    "])\n",
    "\n",
    "# Compilación del modelo para múltiples clases\n",
    "model.compile(optimizer=RMSprop(lr=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 49172 images belonging to 10 classes.\n",
      "Found 2594 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Generadores de datos para entrenamiento y validación\n",
    "TRAINING_DIR = os.path.join(base_dir, 'diagnostico', 'training')\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    target_size=(150, 150))\n",
    "\n",
    "VALIDATION_DIR = os.path.join(base_dir, 'diagnostico', 'testing')\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n",
    "                                                              batch_size=32,\n",
    "                                                              class_mode='categorical',\n",
    "                                                              target_size=(150, 150))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1537/1537 [==============================] - 2444s 2s/step - loss: 0.8825 - accuracy: 0.7085 - val_loss: 0.7625 - val_accuracy: 0.7390\n",
      "Epoch 2/30\n",
      "1537/1537 [==============================] - 1753s 1s/step - loss: 0.8646 - accuracy: 0.7133 - val_loss: 0.7569 - val_accuracy: 0.7402\n",
      "Epoch 3/30\n",
      "1537/1537 [==============================] - 1823s 1s/step - loss: 0.8502 - accuracy: 0.7179 - val_loss: 1.0971 - val_accuracy: 0.6241\n",
      "Epoch 4/30\n",
      "1537/1537 [==============================] - 1786s 1s/step - loss: 0.8401 - accuracy: 0.7211 - val_loss: 0.7941 - val_accuracy: 0.7344\n",
      "Epoch 5/30\n",
      "1537/1537 [==============================] - 1837s 1s/step - loss: 0.8295 - accuracy: 0.7231 - val_loss: 0.7446 - val_accuracy: 0.7440\n",
      "Epoch 6/30\n",
      "1537/1537 [==============================] - 1821s 1s/step - loss: 0.8198 - accuracy: 0.7254 - val_loss: 0.7476 - val_accuracy: 0.7444\n",
      "Epoch 7/30\n",
      "1537/1537 [==============================] - 1840s 1s/step - loss: 0.8092 - accuracy: 0.7286 - val_loss: 0.8340 - val_accuracy: 0.7116\n",
      "Epoch 8/30\n",
      "1537/1537 [==============================] - 1834s 1s/step - loss: 0.8018 - accuracy: 0.7309 - val_loss: 0.9359 - val_accuracy: 0.7136\n",
      "Epoch 9/30\n",
      "1537/1537 [==============================] - 1845s 1s/step - loss: 0.7921 - accuracy: 0.7342 - val_loss: 0.7072 - val_accuracy: 0.7564\n",
      "Epoch 10/30\n",
      "1537/1537 [==============================] - 1832s 1s/step - loss: 0.7805 - accuracy: 0.7374 - val_loss: 0.9883 - val_accuracy: 0.7032\n",
      "Epoch 11/30\n",
      "1537/1537 [==============================] - 1843s 1s/step - loss: 0.7727 - accuracy: 0.7388 - val_loss: 0.9259 - val_accuracy: 0.7167\n",
      "Epoch 12/30\n",
      "1537/1537 [==============================] - 1827s 1s/step - loss: 0.7712 - accuracy: 0.7396 - val_loss: 0.7284 - val_accuracy: 0.7544\n",
      "Epoch 13/30\n",
      "1537/1537 [==============================] - 1850s 1s/step - loss: 0.7638 - accuracy: 0.7413 - val_loss: 0.7924 - val_accuracy: 0.7336\n",
      "Epoch 14/30\n",
      "1537/1537 [==============================] - 1829s 1s/step - loss: 0.7584 - accuracy: 0.7432 - val_loss: 0.7721 - val_accuracy: 0.7402\n",
      "Epoch 15/30\n",
      "1537/1537 [==============================] - 1847s 1s/step - loss: 0.7501 - accuracy: 0.7462 - val_loss: 0.8487 - val_accuracy: 0.7251\n",
      "Epoch 16/30\n",
      "1537/1537 [==============================] - 1826s 1s/step - loss: 0.7439 - accuracy: 0.7464 - val_loss: 0.6585 - val_accuracy: 0.7629\n",
      "Epoch 17/30\n",
      "1537/1537 [==============================] - 1851s 1s/step - loss: 0.7396 - accuracy: 0.7490 - val_loss: 0.7804 - val_accuracy: 0.7321\n",
      "Epoch 18/30\n",
      "1537/1537 [==============================] - 1862s 1s/step - loss: 0.7339 - accuracy: 0.7497 - val_loss: 0.8565 - val_accuracy: 0.7274\n",
      "Epoch 19/30\n",
      "1537/1537 [==============================] - 1905s 1s/step - loss: 0.7301 - accuracy: 0.7498 - val_loss: 0.7009 - val_accuracy: 0.7494\n",
      "Epoch 20/30\n",
      "1537/1537 [==============================] - 1934s 1s/step - loss: 0.7270 - accuracy: 0.7526 - val_loss: 0.6484 - val_accuracy: 0.7756\n",
      "Epoch 21/30\n",
      "1537/1537 [==============================] - 1907s 1s/step - loss: 0.7180 - accuracy: 0.7540 - val_loss: 0.7361 - val_accuracy: 0.7625\n",
      "Epoch 22/30\n",
      "1537/1537 [==============================] - 1872s 1s/step - loss: 0.7136 - accuracy: 0.7545 - val_loss: 0.7004 - val_accuracy: 0.7560\n",
      "Epoch 23/30\n",
      "1537/1537 [==============================] - 1863s 1s/step - loss: 0.7106 - accuracy: 0.7553 - val_loss: 0.6468 - val_accuracy: 0.7729\n",
      "Epoch 24/30\n",
      "1537/1537 [==============================] - 1898s 1s/step - loss: 0.7038 - accuracy: 0.7572 - val_loss: 0.8691 - val_accuracy: 0.7274\n",
      "Epoch 25/30\n",
      "1537/1537 [==============================] - 1865s 1s/step - loss: 0.7009 - accuracy: 0.7597 - val_loss: 0.6509 - val_accuracy: 0.7699\n",
      "Epoch 26/30\n",
      "1537/1537 [==============================] - 1887s 1s/step - loss: 0.6966 - accuracy: 0.7591 - val_loss: 0.7487 - val_accuracy: 0.7498\n",
      "Epoch 27/30\n",
      "1537/1537 [==============================] - 1868s 1s/step - loss: 0.6939 - accuracy: 0.7606 - val_loss: 0.8601 - val_accuracy: 0.7386\n",
      "Epoch 28/30\n",
      "1537/1537 [==============================] - 1896s 1s/step - loss: 0.6888 - accuracy: 0.7613 - val_loss: 0.6722 - val_accuracy: 0.7637\n",
      "Epoch 29/30\n",
      "1537/1537 [==============================] - 1887s 1s/step - loss: 0.6835 - accuracy: 0.7630 - val_loss: 0.6684 - val_accuracy: 0.7648\n",
      "Epoch 30/30\n",
      "1537/1537 [==============================] - 1895s 1s/step - loss: 0.6812 - accuracy: 0.7640 - val_loss: 0.7457 - val_accuracy: 0.7502\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento del modelo\n",
    "history = model.fit_generator(train_generator,\n",
    "                              epochs=15,  # Aumentamos el número de épocas para mayor precisión\n",
    "                              verbose=1,\n",
    "                              validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo\n",
    "save_dir = os.path.join(base_dir, 'models')\n",
    "model.save(os.path.join(save_dir, 'clasificador_10_clases.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\maxi_ia\\env\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "save_dir = os.path.join(base_dir, 'models')\n",
    "model_path = os.path.join(save_dir, 'clasificador_10_clases.h5')\n",
    "model = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1764\\3381238799.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Visualización de los resultados del entrenamiento\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# Visualización de los resultados del entrenamiento\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicción: queratosis-seborreica (Probabilidad: 39.58%)\n"
     ]
    }
   ],
   "source": [
    "# Predicción en nuevas imágenes\n",
    "img_path = os.path.join(base_dir, \"Varicela.jpg\")\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Cargar la imagen y preprocesarla\n",
    "img = image.load_img(img_path, target_size=(150, 150)) \n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = x / 255.0  \n",
    "\n",
    "# Realizar la predicción\n",
    "classes = model.predict(x)\n",
    "\n",
    "# Obtener la clase con mayor probabilidad\n",
    "predicted_class_idx = np.argmax(classes[0])\n",
    "probabilidad = classes[0][predicted_class_idx]\n",
    "\n",
    "# Asignar la clase correspondiente al índice\n",
    "clase_predicha = clases[predicted_class_idx]\n",
    "\n",
    "# Mostrar la clase predicha y la probabilidad\n",
    "print(f\"Predicción: {clase_predicha} (Probabilidad: {probabilidad*100:.2f}%)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
